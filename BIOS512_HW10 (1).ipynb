{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tokenizers\")\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXCpGaol6wTv",
        "outputId": "3c10629e-68af-4142-e44f-50cddaeb7cd6"
      },
      "id": "cXCpGaol6wTv",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(tokenizers)\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse = sep)\n",
        "}"
      ],
      "metadata": {
        "id": "CD5tRw827E9c"
      },
      "id": "CD5tRw827E9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(tokenizers)\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse = sep)\n",
        "}\n",
        "\n",
        "\n",
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "\n",
        "\n",
        "        key <- key_from(ngram, sep)\n",
        "\n",
        "\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "\n",
        "    tbl\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "MJP5Bg1T7Qnx",
        "outputId": "4a0a3e7e-14c3-4d70-f281-a9f2ee7f9684"
      },
      "id": "MJP5Bg1T7Qnx",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "Error in library(tokenizers): there is no package called ‘tokenizers’\n",
          "traceback": [
            "Error in library(tokenizers): there is no package called ‘tokenizers’\nTraceback:\n",
            "1. stop(packageNotFoundError(package, lib.loc, sys.call()))"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}"
      ],
      "metadata": {
        "id": "Aa70AzYN7abi"
      },
      "id": "Aa70AzYN7abi",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt, n)\n",
        "}"
      ],
      "metadata": {
        "id": "lmeNHJm47blV"
      },
      "id": "lmeNHJm47blV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names = TRUE)\n",
        "    if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed = TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "e_PUgAUh7fEa"
      },
      "id": "e_PUgAUh7fEa",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size = 1, prob = as.numeric(counts))\n",
        "}\n"
      ],
      "metadata": {
        "id": "-egXThWL7i2v"
      },
      "id": "-egXThWL7i2v",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "    force(tbl)\n",
        "    n <- as.integer(n)\n",
        "    force(sep)\n",
        " function(start_words = NULL, length = 10L) {\n",
        "  if (is.null(start_words) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep = sep)\n",
        "        }\n",
        "\n",
        "        word_sequence <- start_words\n",
        "  for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep = sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "\n",
        "        paste(word_sequence, collapse = \" \")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "ZfaKYrZm7qIg"
      },
      "id": "ZfaKYrZm7qIg",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tokenizers\")\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "\n",
        "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse = sep)\n",
        "}\n",
        "\n",
        "\n",
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "\n",
        "\n",
        "        key <- key_from(ngram, sep)\n",
        "\n",
        "\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "\n",
        "    tbl\n",
        "}\n",
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}\n",
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt, n)\n",
        "}\n",
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names = TRUE)\n",
        "    if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size = 1, prob = as.numeric(counts))\n",
        "}\n",
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "    force(tbl)\n",
        "    n <- as.integer(n)\n",
        "    force(sep)\n",
        " function(start_words = NULL, length = 10L) {\n",
        "  if (is.null(start_words) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep = sep)\n",
        "        }\n",
        "\n",
        "        word_sequence <- start_words\n",
        "  for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep = sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "\n",
        "        paste(word_sequence, collapse = \" \")\n",
        "    }\n",
        "}\n",
        "\n",
        "cat(\"Building trigram model (n=3)...\\n\")\n",
        "tbl3 <- digest_url(url, n = 3)\n",
        "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
        "\n",
        "cat(\"\\n\\nWith start words 'the king':\\n\")\n",
        "print(gen3(start_words = c(\"the\", \"king\"), length = 15))\n",
        "\n",
        "cat(\"\\nRandom start, 15 words:\\n\")\n",
        "print(gen3(length = 15))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rCBMu5r8OXi",
        "outputId": "add1c636-b585-4dbc-ff10-de038e408864"
      },
      "id": "6rCBMu5r8OXi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building trigram model (n=3)...\n",
            "\n",
            "\n",
            "With start words 'the king':\n",
            "[1] \"the king mourned over his three wishes so he took leave of each glass and\"\n",
            "\n",
            "Random start, 15 words:\n",
            "[1] \"beautiful garden and asked what was in every day she stole away and they have\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tokenizers\")\n",
        "library(httr)\n",
        "library(tokenizers)\n",
        "\n",
        "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
        "\n",
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse = sep)\n",
        "}\n",
        "\n",
        "\n",
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "\n",
        "\n",
        "        key <- key_from(ngram, sep)\n",
        "\n",
        "\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "\n",
        "    tbl\n",
        "}\n",
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}\n",
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt, n)\n",
        "}\n",
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names = TRUE)\n",
        "    if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed = TRUE)[[1]]\n",
        "}\n",
        "\n",
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size = 1, prob = as.numeric(counts))\n",
        "}\n",
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "    force(tbl)\n",
        "    n <- as.integer(n)\n",
        "    force(sep)\n",
        " function(start_words = NULL, length = 10L) {\n",
        "  if (is.null(start_words) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep = sep)\n",
        "        }\n",
        "\n",
        "        word_sequence <- start_words\n",
        "  for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep = sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "\n",
        "        paste(word_sequence, collapse = \" \")\n",
        "    }\n",
        "}\n",
        "\n",
        "cat(\"Building trigram model (n=3)...\\n\")\n",
        "tbl3 <- digest_url(url, n = 3)\n",
        "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
        "\n",
        "cat(\"\\n\\nWith start words 'the king':\\n\")\n",
        "print(gen3(start_words = c(\"the\", \"king\"), length = 15))\n",
        "\n",
        "cat(\"\\nRandom start, 15 words:\\n\")\n",
        "print(gen3(length = 15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olViP7RkGFRQ",
        "outputId": "eaa6ef26-b0cb-45bc-c73e-af06a1c877a9"
      },
      "id": "olViP7RkGFRQ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building trigram model (n=3)...\n",
            "\n",
            "\n",
            "With start words 'the king':\n",
            "[1] \"the king wherever he may go in order to be chain mail or of quilted\"\n",
            "\n",
            "Random start, 15 words:\n",
            "[1] \"engraved excellently and in the eleventh century for of raoul de beaumont in the archæologia\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source.\n",
        "\n",
        "The main difference is the choice of words. For the second random start, the machine picked something with lots of numbers and _lib which I am not sure what that means. For the first example the machine chose words that were more coherent."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "A type of AI that is trained with lots of text to be able to generate human-like language\n",
        "\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?\n",
        "\n",
        "To run locally you can get OLLAMA installed you can use this and write your own code allowing you to run your favorite language model locally."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
      "metadata": {
        "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | Executes and interprets mkdir. It runs the command and passes project as an object to the command |\n",
        "| **Terminal emulator** | Graphical application window. For example for mac we have the terminal. This is where you type mkdir project into |\n",
        "| **Process** | When you run mkdir project and the os creates a new system. This process has its own memory space and runs independantly |\n",
        "| **Signal** | mkdir project doesn't direclty use it but if you were to crl c while mkdir was running, there would be a signal sent to terminate program |\n",
        "| **Standard input** | Standard input is where a program reads data from - typically keyboard input or piped data. |\n",
        "| **Standard output** | Standard output is where programs write their results. |\n",
        "| **Command line argument** | Project is a command line argument passed through mkdir. These arguments are inputs that are provided after a command |\n",
        "| **The environment** | all the stuff a process can see when its running; ok to imagine that when one process starts another, the child process sees all the same stuff as the parent  |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "find, xargs, grep\n",
        "#### b) Explain what this command is doing, part by part.\n",
        "\n",
        "find parses through the files, the . is the starting directory, the -iname \"*.R\" means its searching for files that have *.R and matches files that end in R or r. The pipe operator takes the standard output from find and sends it as standard input to the next command, the xargs Reads filenames from the input and converts them into arguments for the next command. grep makes the program that will search for patterns in files. The read_csv is what the grep will be looking for when its looking through the lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "\n",
        "Unable to find image 'hello-world:latest' locally\n",
        "latest: Pulling from library/hello-world\n",
        "198f93fd5094: Pull complete\n",
        "Digest: sha256:f7931603f70e13dbd844253370742c4fc4202d290c80442b2e68706d8f33ce26\n",
        "Status: Downloaded newer image for hello-world:latest\n",
        "\n",
        "Hello from Docker!\n",
        "This message shows that your installation appears to be working correctly.\n",
        "\n",
        "To generate this message, Docker took the following steps:\n",
        " 1. The Docker client contacted the Docker daemon.\n",
        " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
        "    (arm64v8)\n",
        " 3. The Docker daemon created a new container from that image which runs the\n",
        "    executable that produces the output you are currently reading.\n",
        " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
        "    to your terminal.\n",
        "\n",
        "To try something more ambitious, you can run an Ubuntu container with:\n",
        " $ docker run -it ubuntu bash\n",
        "\n",
        "Share images, automate workflows, and more with a free Docker ID:\n",
        " https://hub.docker.com/\n",
        "\n",
        "For more examples and ideas, visit:\n",
        " https://docs.docker.com/get-started/\n",
        "\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "docker pull rocker/rstudio\n",
        "docker run -d -p 8787:8787 -e PASSWORD=yourpassword rocker/rstudio\n",
        "\n",
        "Using default tag: latest\n",
        "latest: Pulling from rocker/rstudio\n",
        "08e74fd5985d: Pull complete\n",
        "e2804bef35e8: Pull complete\n",
        "91ed5b86de88: Pull complete\n",
        "cc9c938c1f51: Pull complete\n",
        "bcce866b1806: Pull complete\n",
        "5b219f62ce36: Pull complete\n",
        "2034506aa72f: Pull complete\n",
        "9c1a4a0706b7: Pull complete\n",
        "5d246ec925db: Pull complete\n",
        "bc9245ceaac5: Pull complete\n",
        "b8a35db46e38: Pull complete\n",
        "3665120d345d: Pull complete\n",
        "a730ff463d58: Pull complete\n",
        "2c9ba66d5dbe: Pull complete\n",
        "39038e16d1ba: Pull complete\n",
        "664fb1818bbb: Pull complete\n",
        "191985778909: Pull complete\n",
        "abd0190d83fb: Pull complete\n",
        "Digest: sha256:9f85211a666fb426081a6f5a01f9f9f51655262258419fa21e0ce38a5afc78d8\n",
        "Status: Downloaded newer image for rocker/rstudio:latest\n",
        "docker.io/rocker/rstudio:latest\n",
        "\n",
        "#### c) How do you log in to the RStudio server?\n",
        "\n",
        "You have a local host, and it allows you to login and do continue your coding. The username is rstudio by defualt and the password is whatever I put it.  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}