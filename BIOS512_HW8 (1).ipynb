{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "77b97eda-a875-49d9-922a-aca98f18d1ea",
      "metadata": {
        "id": "77b97eda-a875-49d9-922a-aca98f18d1ea"
      },
      "source": [
        "# Homework 08\n",
        "This homework is based on the clustering lectures. Check the lecture notes and TA notes - they should help!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f75ac688-c3c4-4916-a858-97104be7e273",
      "metadata": {
        "id": "f75ac688-c3c4-4916-a858-97104be7e273"
      },
      "source": [
        "## Question 1\n",
        "This question will walk you through creating your own `kmeans` function."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eb3eefd-fd8c-4688-8b9e-e2368e56d526",
      "metadata": {
        "id": "9eb3eefd-fd8c-4688-8b9e-e2368e56d526"
      },
      "source": [
        "#### a) What are the steps of `kmeans`?\n",
        "**Hint**: There are 4 steps/builder functions that you'll need.\n",
        "\n",
        "1.Assign each point to a cluster N at random.\n",
        "2.Calculate the mean position of each cluster using the previous assignments.\n",
        "3.Loop through the points - assign each point to the cluster to whose center it is closest.\n",
        "4.Repeat this process until the centers stop moving around."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf8b199b-d1d9-4a55-ad95-9e86ad0655bd",
      "metadata": {
        "id": "bf8b199b-d1d9-4a55-ad95-9e86ad0655bd"
      },
      "source": [
        "#### b) Create the builder function for step 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_randomly <- function(n_points, n_clusters){\n",
        "  sample(1:n_clusters, n_points, replace = TRUE)\n",
        "}"
      ],
      "metadata": {
        "id": "3rTUTVC4HIUb"
      },
      "id": "3rTUTVC4HIUb",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9e44ddaf-4506-47d0-98fb-09871e08808c",
      "metadata": {
        "id": "9e44ddaf-4506-47d0-98fb-09871e08808c"
      },
      "source": [
        "#### c) Create the builder function for step 2."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_cluster_means <- function(data, labels){\n",
        "  data %>%\n",
        "    mutate(label__ = labels) %>%\n",
        "    group_by(label__) %>%\n",
        "    summarize(across(-label__, mean), .groups = \"drop\") %>%\n",
        "    arrange(label__)\n",
        "}"
      ],
      "metadata": {
        "id": "p6ijoCzeHUu2"
      },
      "id": "p6ijoCzeHUu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1c8640c6-2d2f-49c3-b7ed-da0d4fb13935",
      "metadata": {
        "id": "1c8640c6-2d2f-49c3-b7ed-da0d4fb13935"
      },
      "source": [
        "#### d) Create the builder function for step 3.\n",
        "*Hint*: There are two ways to do this part - one is significantly more efficient than the other. You can do either.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assign_cluster <- function(data, means){\n",
        "  dii <- 1:nrow(data)\n",
        "  cii <- 1:nrow(means)\n",
        "  labels <- c()\n",
        "  for (point_index in dii){\n",
        "    smallest_dist <- Inf\n",
        "    smallest_label <- NA\n",
        "    point <- as.numeric(data[point_index, ])\n",
        "    for (clus_index in cii){\n",
        "      clus_vec <- as.numeric(means[clus_index, colnames(means) != \"label__\"])\n",
        "      diff <- point - clus_vec\n",
        "      dist <- sum(diff * diff)\n",
        "\n",
        "      if (dist < smallest_dist){\n",
        "        smallest_dist <- dist\n",
        "        smallest_label <- means[clus_index, ]$label__\n",
        "      }\n",
        "    }\n",
        "\n",
        "    labels <- c(labels, smallest_label)\n",
        "  }\n",
        "\n",
        "  labels\n",
        "}\n"
      ],
      "metadata": {
        "id": "liphXpvtHUFL"
      },
      "id": "liphXpvtHUFL",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "2bbea660-9bd2-4dae-9a5c-838f613b0d7c",
      "metadata": {
        "id": "2bbea660-9bd2-4dae-9a5c-838f613b0d7c"
      },
      "source": [
        "#### e) Create the builder function for step 4."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans_done <- function(old_means, new_means, eps = 1e-6){\n",
        "  om <- as.matrix(old_means[, colnames(old_means) != \"label__\"])\n",
        "  nm <- as.matrix(new_means[, colnames(new_means) != \"label__\"])\n",
        "  m <- mean(sqrt(rowSums((om - nm)^2)))\n",
        "  if (m < eps) TRUE else FALSE\n",
        "}"
      ],
      "metadata": {
        "id": "LGd5Gnu3H9Pl"
      },
      "id": "LGd5Gnu3H9Pl",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f3c86f61-68d2-484a-9c9c-db7f35c8e685",
      "metadata": {
        "id": "f3c86f61-68d2-484a-9c9c-db7f35c8e685"
      },
      "source": [
        "#### f) Combine them all into your own `kmeans` function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mykmeans <- function(data, n_clusters, eps = 1e-6){\n",
        "  labels <- label_randomly(nrow(data), n_clusters)\n",
        "  old_means <- get_cluster_means(data, labels)\n",
        "  done <- FALSE\n",
        "\n",
        "  while (!done){\n",
        "    labels <- assign_cluster(data, old_means)\n",
        "    new_means <- get_cluster_means(data, labels)\n",
        "    if (kmeans_done(old_means, new_means)){\n",
        "      done <- TRUE\n",
        "    } else {\n",
        "      old_means <- new_means\n",
        "    }\n",
        "  }\n",
        "\n",
        "  list(labels = labels, means = new_means)\n",
        "}"
      ],
      "metadata": {
        "id": "xLdi7piQIMuv"
      },
      "id": "xLdi7piQIMuv",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "da13180d-3a51-4218-94a0-3f362612f099",
      "metadata": {
        "id": "da13180d-3a51-4218-94a0-3f362612f099"
      },
      "source": [
        "## Question 2\n",
        "This is when we'll test your `kmeans` function.\n",
        "#### a) Read in the `voltages_df.csv` data set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df <- read.csv(\"voltages_df.csv\")"
      ],
      "metadata": {
        "id": "pWdJoLqKNunR"
      },
      "id": "pWdJoLqKNunR",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1f002a7b-eda1-4d2d-8ef9-3090b563708d",
      "metadata": {
        "id": "1f002a7b-eda1-4d2d-8ef9-3090b563708d"
      },
      "source": [
        "#### b) Call your `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$means`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "df <- read.csv(\"voltages_df.csv\")\n",
        "\n",
        "label_randomly <- function(n_points, n_clusters){\n",
        "  sample(1:n_clusters, n_points, replace = TRUE)\n",
        "}\n",
        "\n",
        "get_cluster_means <- function(data, labels){\n",
        "  data %>%\n",
        "    mutate(label__ = labels) %>%\n",
        "    group_by(label__) %>%\n",
        "    summarize(across(everything(), mean), .groups = \"drop\") %>%\n",
        "    arrange(label__)\n",
        "}\n",
        "\n",
        "assign_cluster <- function(data, means){\n",
        "  dii <- 1:nrow(data)\n",
        "  cii <- 1:nrow(means)\n",
        "  labels <- c()\n",
        "\n",
        "  for (point_index in dii){\n",
        "    smallest_dist <- Inf\n",
        "    smallest_label <- NA\n",
        "\n",
        "    point <- as.numeric(data[point_index, ])\n",
        "\n",
        "    for (clus_index in cii){\n",
        "      clus_vec <- as.numeric(means[clus_index, colnames(means) != \"label__\"])\n",
        "      diff <- point - clus_vec\n",
        "      dist <- sum(diff * diff)\n",
        "      if (dist < smallest_dist){\n",
        "        smallest_dist <- dist\n",
        "        smallest_label <- means[clus_index, ]$label__\n",
        "      }\n",
        "    }\n",
        "    labels <- c(labels, smallest_label)\n",
        "  }\n",
        "  labels\n",
        "}\n",
        "\n",
        "kmeans_done <- function(old_means, new_means, eps = 1e-6){\n",
        "  om <- as.matrix(old_means[, colnames(old_means) != \"label__\"])\n",
        "  nm <- as.matrix(new_means[, colnames(new_means) != \"label__\"])\n",
        "  m <- mean(sqrt(rowSums((om - nm)^2)))\n",
        "  m < eps\n",
        "}\n",
        "\n",
        "mykmeans <- function(data, n_clusters, eps = 1e-6){\n",
        "  labels <- label_randomly(nrow(data), n_clusters)\n",
        "  old_means <- get_cluster_means(data, labels)\n",
        "  done <- FALSE\n",
        "\n",
        "  while (!done){\n",
        "    labels <- assign_cluster(data, old_means)\n",
        "    new_means <- get_cluster_means(data, labels)\n",
        "    if (kmeans_done(old_means, new_means)){\n",
        "      done <- TRUE\n",
        "    } else {\n",
        "      old_means <- new_means\n",
        "    }\n",
        "  }\n",
        "\n",
        "  list(labels = labels, means = new_means)\n",
        "}\n",
        "\n",
        "X <- df[, sapply(df, is.numeric), drop = FALSE]\n",
        "\n",
        "set.seed(1)\n",
        "results <- mykmeans(X, n_clusters = 3)\n",
        "cat(\"results$labels:\\n\")\n",
        "print(results$labels)\n",
        "cat(\"\\nresults$means:\\n\")\n",
        "print(results$means)"
      ],
      "metadata": {
        "id": "WZq5MvLXa3Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b71276c-3237-42aa-dd9b-43bf490c31c1"
      },
      "id": "WZq5MvLXa3Yp",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results$labels:\n",
            "  [1] 1 2 2 2 2 2 3 3 2 1 1 1 3 1 2 1 1 1 1 1 2 2 2 2 2 1 1 1 3 3 3 3 2 3 3 2 2\n",
            " [38] 1 3 2 1 1 1 3 2 3 3 2 3 3 2 3 1 1 3 1 2 1 3 2 1 1 2 1 3 3 2 3 1 3 1 2 3 3\n",
            " [75] 2 2 1 3 3 3 3 3 2 3 3 2 2 2 1 3 3 3 2 3 2 2 3 2 2 3 3 3 2 3 1 1 3 1 1 2 1\n",
            "[112] 1 2 3 1 3 1 1 2 2 2 2 1 1 3 2 2 3 1 3 2 1 2 3 1 2 2 2 1 3 1 2 2 3 1 1 2 1\n",
            "[149] 1 3 1 3 2 2 3 1 3 3 2 1 3 3 1 2 1 3 2 1 2 1 1 3 2 1 3 3 2 3 1 2 3 2 3 1 3\n",
            "[186] 2 2 1 2 1 1 2 1 1 3 3 1 2 1 1 3 1 3 3 2 1 2 3 2 1 2 3 1 3 3 2 3 3 2 2 2 2\n",
            "[223] 2 2 2 3 3 3 3 1 2 1 3 2 2 3 3 1 1 3 3 1 3 3 2 3 1 3 3 2 3 2 1 3 2 3 3 1 1\n",
            "[260] 1 2 2 3 1 2 2 2 3 3 3 1 2 2 2 3 1 3 3 2 2 3 1 3 1 1 2 3 2 2 3 3 1 3 3 1 2\n",
            "[297] 1 3 3 2 2 3 1 1 1 3 1 2 2 2 1 1 1 1 1 1 2 1 2 1 1 3 2 3 1 1 1 1 2 1 2 1 3\n",
            "[334] 1 2 2 3 3 1 2 3 2 3 3 1 3 2 3 1 1 3 2 2 2 1 3 2 1 3 3 2 2 2 2 1 3 1 2 1 1\n",
            "[371] 1 1 1 2 2 3 3 1 1 1 1 3 3 1 1 3 3 2 2 3 1 2 2 2 2 3 2 2 3 1 1 1 1 2 2 1 1\n",
            "[408] 3 3 3 2 3 3 1 2 2 2 3 2 2 2 1 1 2 1 3 2 2 2 2 3 3 2 3 1 2 1 1 1 3 3 3 3 1\n",
            "[445] 2 1 1 1 3 2 1 1 1 2 2 1 2 2 1 3 2 2 1 3 2 2 2 1 3 3 1 3 1 2 2 3 1 3 1 2 2\n",
            "[482] 3 1 3 3 3 2 3 3 3 3 3 2 1 1 3 3 1 2 2 2 1 1 1 2 2 3 3 1 3 1 2 2 3 3 1 3 3\n",
            "[519] 2 1 1 1 2 3 1 2 3 3 1 2 3 3 3 3 1 1 2 1 1 2 2 2 2 3 1 1 3 1 1 1 2 2 1 2 3\n",
            "[556] 3 2 3 3 3 2 3 3 2 3 3 2 3 3 1 3 2 3 2 3 2 2 2 1 3 3 3 3 1 2 3 3 3 2 3 3 2\n",
            "[593] 2 2 3 1 2 2 1 2 3 2 2 3 1 1 3 3 3 2 3 1 2 1 3 2 1 2 2 1 3 2 1 3 3 1 2 1 3\n",
            "[630] 2 1 3 1 2 2 1 2 1 1 1 1 1 2 2 1 3 1 3 3 1 3 2 3 1 3 1 1 1 2 1 1 2 2 1 1 2\n",
            "[667] 1 2 3 3 2 1 2 1 1 3 2 2 1 3 1 2 3 3 1 1 2 1 2 2 3 3 3 3 2 2 2 1 3 2 1 3 3\n",
            "[704] 1 1 3 2 3 3 1 2 1 3 2 1 2 2 1 2 2 1 1 2 2 1 2 3 1 1 1 1 1 2 2 1 1 2 2 1 2\n",
            "[741] 1 2 3 1 1 1 2 1 3 2 2 1 1 3 1 1 3 1 3 3 1 1 2 3 1 2 3 2 2 1 3 2 3 1 2 1 1\n",
            "[778] 3 1 3 2 1 1 2 3 2 1 2 1 3 1 1 2 2 2 1 2 1 3 2 2 2 2 1 1 3 2 1 1 1 1 3 3 1\n",
            "[815] 3 1 2 1 2 3 2 2 2 2 2 3 3 2 3 3 3 3 3 3 2 1 1 2 3 3 1 2 3 3 3 3 1 1 2 3 2\n",
            "[852] 1 3 3 3 3 1 1 3 3 3 3 3 1 2 3 2 1 2 2 3 1 3 3 1 1 2 1 1 1 3 2 3 2 2 1 1 3\n",
            "[889] 3 2 1 3 3 2 2 2 2 1 3 3\n",
            "\n",
            "results$means:\n",
            "\u001b[90m# A tibble: 3 × 251\u001b[39m\n",
            "  label__    X0 X1.00401606425703 X2.00803212851406 X3.01204819277108\n",
            "    \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m\n",
            "\u001b[90m1\u001b[39m       1 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             0.938             0.762             0.363\n",
            "\u001b[90m2\u001b[39m       2 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             1.24              1.09              0.900\n",
            "\u001b[90m3\u001b[39m       3 -\u001b[31m1\u001b[39m\u001b[31m.\u001b[39m\u001b[31m0\u001b[39m\u001b[31m3\u001b[39m             1.31              1.16              0.979\n",
            "\u001b[90m# ℹ 246 more variables: X4.01606425702811 <dbl>, X5.02008032128514 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X6.02409638554217 <dbl>, X7.0281124497992 <dbl>, X8.03212851405623 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X9.03614457831325 <dbl>, X10.0401606425703 <dbl>, X11.0441767068273 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X12.0481927710843 <dbl>, X13.0522088353414 <dbl>, X14.0562248995984 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X15.0602409638554 <dbl>, X16.0642570281125 <dbl>, X17.0682730923695 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X18.0722891566265 <dbl>, X19.0763052208835 <dbl>, X20.0803212851406 <dbl>,\u001b[39m\n",
            "\u001b[90m#   X21.0843373493976 <dbl>, X22.0883534136546 <dbl>, …\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03d9949c-60ce-4a75-8688-e3c7485122ab",
      "metadata": {
        "id": "03d9949c-60ce-4a75-8688-e3c7485122ab"
      },
      "source": [
        "#### c) Call R's `kmeans` function with 3 clusters. Print the results with `results$labels` and `results$cluster`.\n",
        "*Hint*: Use the `as.matrix()` function to make the `voltages_df` data frame a matrix before calling `kmeans()`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df <- read.csv(\"voltages_df.csv\")\n",
        "X <- as.matrix(df)\n",
        "\n",
        "set.seed(1)\n",
        "km <- kmeans(X, centers = 3)\n",
        "results <- list(\n",
        "  labels  = km$cluster,\n",
        "  cluster = km$cluster\n",
        ")\n",
        "cat(\"results$labels:\\n\")\n",
        "print(results$labels)\n",
        "cat(\"\\nresults$cluster:\\n\")\n",
        "print(results$cluster)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEQOjahb7s8k",
        "outputId": "39a637a5-06a2-4e4e-c10a-0ba35a27884f"
      },
      "id": "TEQOjahb7s8k",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "results$labels:\n",
            "  [1] 1 2 2 2 2 2 3 3 2 1 1 1 3 1 2 1 1 1 1 1 2 2 2 2 2 1 1 1 3 3 3 3 2 3 3 2 2\n",
            " [38] 1 3 2 1 1 1 3 2 3 3 2 3 3 2 3 1 1 3 1 2 1 3 2 1 1 2 1 3 3 2 3 1 3 1 2 3 3\n",
            " [75] 2 2 1 3 3 3 3 3 2 3 3 2 2 2 1 3 3 3 2 3 2 2 3 2 2 3 3 3 2 3 1 1 3 1 1 2 1\n",
            "[112] 1 2 3 1 3 1 1 2 2 2 2 1 1 3 2 2 3 1 3 2 1 2 3 1 2 2 2 1 3 1 2 2 3 1 1 2 1\n",
            "[149] 1 3 1 3 2 2 3 1 3 3 2 1 3 3 1 2 1 3 2 1 2 1 1 3 2 1 3 3 2 3 1 2 3 2 3 1 3\n",
            "[186] 2 2 1 2 1 1 2 1 1 3 3 1 2 1 1 3 1 3 3 2 1 2 3 2 1 2 3 1 3 3 2 3 3 2 2 2 2\n",
            "[223] 2 2 2 3 3 3 3 1 2 1 3 2 2 3 3 1 1 3 3 1 3 3 2 3 1 3 3 2 3 2 1 3 2 3 3 1 1\n",
            "[260] 1 2 2 3 1 2 2 2 3 3 3 1 2 2 2 3 1 3 3 2 2 3 1 3 1 1 2 3 2 2 3 3 1 3 3 1 2\n",
            "[297] 1 3 3 2 2 3 1 1 1 3 1 2 2 2 1 1 1 1 1 1 2 1 2 1 1 3 2 3 1 1 1 1 2 1 2 1 3\n",
            "[334] 1 2 2 3 3 1 2 3 2 3 3 1 3 2 3 1 1 3 2 2 2 1 3 2 1 3 3 2 2 2 2 1 3 1 2 1 1\n",
            "[371] 1 1 1 2 2 3 3 1 1 1 1 3 3 1 1 3 3 2 2 3 1 2 2 2 2 3 2 2 3 1 1 1 1 2 2 1 1\n",
            "[408] 3 3 3 2 3 3 1 2 2 2 3 2 2 2 1 1 2 1 3 2 2 2 2 3 3 2 3 1 2 1 1 1 3 3 3 3 1\n",
            "[445] 2 1 1 1 3 2 1 1 1 2 2 1 2 2 1 3 2 2 1 3 2 2 2 1 3 3 1 3 1 2 2 3 1 3 1 2 2\n",
            "[482] 3 1 3 3 3 2 3 3 3 3 3 2 1 1 3 3 1 2 2 2 1 1 1 2 2 3 3 1 3 1 2 2 3 3 1 3 3\n",
            "[519] 2 1 1 1 2 3 1 2 3 3 1 2 3 3 3 3 1 1 2 1 1 2 2 2 2 3 1 1 3 1 1 1 2 2 1 2 3\n",
            "[556] 3 2 3 3 3 2 3 3 2 3 3 2 3 3 1 3 2 3 2 3 2 2 2 1 3 3 3 3 1 2 3 3 3 2 3 3 2\n",
            "[593] 2 2 3 1 2 2 1 2 3 2 2 3 1 1 3 3 3 2 3 1 2 1 3 2 1 2 2 1 3 2 1 3 3 1 2 1 3\n",
            "[630] 2 1 3 1 2 2 1 2 1 1 1 1 1 2 2 1 3 1 3 3 1 3 2 3 1 3 1 1 1 2 1 1 2 2 1 1 2\n",
            "[667] 1 2 3 3 2 1 2 1 1 3 2 2 1 3 1 2 3 3 1 1 2 1 2 2 3 3 3 3 2 2 2 1 3 2 1 3 3\n",
            "[704] 1 1 3 2 3 3 1 2 1 3 2 1 2 2 1 2 2 1 1 2 2 1 2 3 1 1 1 1 1 2 2 1 1 2 2 1 2\n",
            "[741] 1 2 3 1 1 1 2 1 3 2 2 1 1 3 1 1 3 1 3 3 1 1 2 3 1 2 3 2 2 1 3 2 3 1 2 1 1\n",
            "[778] 3 1 3 2 1 1 2 3 2 1 2 1 3 1 1 2 2 2 1 2 1 3 2 2 2 2 1 1 3 2 1 1 1 1 3 3 1\n",
            "[815] 3 1 2 1 2 3 2 2 2 2 2 3 3 2 3 3 3 3 3 3 2 1 1 2 3 3 1 2 3 3 3 3 1 1 2 3 2\n",
            "[852] 1 3 3 3 3 1 1 3 3 3 3 3 1 2 3 2 1 2 2 3 1 3 3 1 1 2 1 1 1 3 2 3 2 2 1 1 3\n",
            "[889] 3 2 1 3 3 2 2 2 2 1 3 3\n",
            "\n",
            "results$cluster:\n",
            "  [1] 1 2 2 2 2 2 3 3 2 1 1 1 3 1 2 1 1 1 1 1 2 2 2 2 2 1 1 1 3 3 3 3 2 3 3 2 2\n",
            " [38] 1 3 2 1 1 1 3 2 3 3 2 3 3 2 3 1 1 3 1 2 1 3 2 1 1 2 1 3 3 2 3 1 3 1 2 3 3\n",
            " [75] 2 2 1 3 3 3 3 3 2 3 3 2 2 2 1 3 3 3 2 3 2 2 3 2 2 3 3 3 2 3 1 1 3 1 1 2 1\n",
            "[112] 1 2 3 1 3 1 1 2 2 2 2 1 1 3 2 2 3 1 3 2 1 2 3 1 2 2 2 1 3 1 2 2 3 1 1 2 1\n",
            "[149] 1 3 1 3 2 2 3 1 3 3 2 1 3 3 1 2 1 3 2 1 2 1 1 3 2 1 3 3 2 3 1 2 3 2 3 1 3\n",
            "[186] 2 2 1 2 1 1 2 1 1 3 3 1 2 1 1 3 1 3 3 2 1 2 3 2 1 2 3 1 3 3 2 3 3 2 2 2 2\n",
            "[223] 2 2 2 3 3 3 3 1 2 1 3 2 2 3 3 1 1 3 3 1 3 3 2 3 1 3 3 2 3 2 1 3 2 3 3 1 1\n",
            "[260] 1 2 2 3 1 2 2 2 3 3 3 1 2 2 2 3 1 3 3 2 2 3 1 3 1 1 2 3 2 2 3 3 1 3 3 1 2\n",
            "[297] 1 3 3 2 2 3 1 1 1 3 1 2 2 2 1 1 1 1 1 1 2 1 2 1 1 3 2 3 1 1 1 1 2 1 2 1 3\n",
            "[334] 1 2 2 3 3 1 2 3 2 3 3 1 3 2 3 1 1 3 2 2 2 1 3 2 1 3 3 2 2 2 2 1 3 1 2 1 1\n",
            "[371] 1 1 1 2 2 3 3 1 1 1 1 3 3 1 1 3 3 2 2 3 1 2 2 2 2 3 2 2 3 1 1 1 1 2 2 1 1\n",
            "[408] 3 3 3 2 3 3 1 2 2 2 3 2 2 2 1 1 2 1 3 2 2 2 2 3 3 2 3 1 2 1 1 1 3 3 3 3 1\n",
            "[445] 2 1 1 1 3 2 1 1 1 2 2 1 2 2 1 3 2 2 1 3 2 2 2 1 3 3 1 3 1 2 2 3 1 3 1 2 2\n",
            "[482] 3 1 3 3 3 2 3 3 3 3 3 2 1 1 3 3 1 2 2 2 1 1 1 2 2 3 3 1 3 1 2 2 3 3 1 3 3\n",
            "[519] 2 1 1 1 2 3 1 2 3 3 1 2 3 3 3 3 1 1 2 1 1 2 2 2 2 3 1 1 3 1 1 1 2 2 1 2 3\n",
            "[556] 3 2 3 3 3 2 3 3 2 3 3 2 3 3 1 3 2 3 2 3 2 2 2 1 3 3 3 3 1 2 3 3 3 2 3 3 2\n",
            "[593] 2 2 3 1 2 2 1 2 3 2 2 3 1 1 3 3 3 2 3 1 2 1 3 2 1 2 2 1 3 2 1 3 3 1 2 1 3\n",
            "[630] 2 1 3 1 2 2 1 2 1 1 1 1 1 2 2 1 3 1 3 3 1 3 2 3 1 3 1 1 1 2 1 1 2 2 1 1 2\n",
            "[667] 1 2 3 3 2 1 2 1 1 3 2 2 1 3 1 2 3 3 1 1 2 1 2 2 3 3 3 3 2 2 2 1 3 2 1 3 3\n",
            "[704] 1 1 3 2 3 3 1 2 1 3 2 1 2 2 1 2 2 1 1 2 2 1 2 3 1 1 1 1 1 2 2 1 1 2 2 1 2\n",
            "[741] 1 2 3 1 1 1 2 1 3 2 2 1 1 3 1 1 3 1 3 3 1 1 2 3 1 2 3 2 2 1 3 2 3 1 2 1 1\n",
            "[778] 3 1 3 2 1 1 2 3 2 1 2 1 3 1 1 2 2 2 1 2 1 3 2 2 2 2 1 1 3 2 1 1 1 1 3 3 1\n",
            "[815] 3 1 2 1 2 3 2 2 2 2 2 3 3 2 3 3 3 3 3 3 2 1 1 2 3 3 1 2 3 3 3 3 1 1 2 3 2\n",
            "[852] 1 3 3 3 3 1 1 3 3 3 3 3 1 2 3 2 1 2 2 3 1 3 3 1 1 2 1 1 1 3 2 3 2 2 1 1 3\n",
            "[889] 3 2 1 3 3 2 2 2 2 1 3 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4944ea46-ed01-413b-8b55-d55f383413de",
      "metadata": {
        "id": "4944ea46-ed01-413b-8b55-d55f383413de"
      },
      "source": [
        "#### d) Are your labels/clusters the same? If not, why? Are your means the same?\n",
        "\n",
        "Looking at both labels and clusters tables, they apear to be very similar. When looking at the means they also look simiar to the kmeans. Overall, data looks consistant."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6228e5ce-269f-4d83-b94e-40f3c4a137cd",
      "metadata": {
        "id": "6228e5ce-269f-4d83-b94e-40f3c4a137cd"
      },
      "source": [
        "## Question 3\n",
        "#### a) Explain the process of using a for loop to assign clusters for kmeans.\n",
        "\n",
        "Using a for loop means iterating every point in order to assign a cluster for kmeans. What the for loop does is calculte the distance between each center and recored the closesed centers index and insert it into the labels.Once the loop is finished the labels variable has a cluster for every given point. After the labels are obtained, the means are calculated."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2815b679-8bd1-4ec2-85d3-e42166f3e0ff",
      "metadata": {
        "id": "2815b679-8bd1-4ec2-85d3-e42166f3e0ff"
      },
      "source": [
        "#### b) Explain the process of vectorizing the code to assign clusters for kmeans.\n",
        "\n",
        "You obtain all the centers and for all of the points you compute the distances to all the centers. Then, for each point take the minimum value of the centers which becomes the new cluster label. Using this methods increases latency of the program.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6be7b85-c4f0-4626-b7f5-0ba921efcb6d",
      "metadata": {
        "id": "c6be7b85-c4f0-4626-b7f5-0ba921efcb6d"
      },
      "source": [
        "#### c) State which (for loops or vectorizing) is more efficient and why.\n",
        "\n",
        "Vectoizing is more efficent because for the for loop, the for loop has to go through all the points in the dataset and while this may be okay for small data sets, most data sets have lots of points which would make the code run slower. Whereas if the dataset is vectorized it is put into a matrix allowing for other operations done for k means to be done quicker."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d2824d8-b8b6-4746-8fdc-8b3a8a1ca49d",
      "metadata": {
        "id": "3d2824d8-b8b6-4746-8fdc-8b3a8a1ca49d"
      },
      "source": [
        "## Question 4\n",
        "#### When does `kmeans` fail? What assumption does `kmeans` use that causes it to fail in this situation?\n",
        "\n",
        "K means works best when the datapoints are close to each other and when clusters are roundish, esentially when clusters are around the same size. If k means isn't presenting that way then you might get misleading results and wrong interpretation of the data. An assumption that kmeans uses is that assumes you have vectorial data which is  distributed into uniformly shaped Gaussian of similar size and shape. It also assumes that an element is either in a cluster or not."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20c5a711-449c-48e0-b02b-8ad3346e8d38",
      "metadata": {
        "id": "20c5a711-449c-48e0-b02b-8ad3346e8d38"
      },
      "source": [
        "## Question 5\n",
        "#### What assumption do Guassian mixture models make?\n",
        "\n",
        "They make the assumption that the dataset is done by mixing k shaped clouds of data and that each cloud has its own mean and shape. So while kmeans says to pick the nearest center, the guassian mixture model says to give them a fuzzy k-means which gives the model a more softer assignment rather than one that has to resember a circle."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed1a4f52-f2d5-45d7-aeb2-a05ccab9e2fe",
      "metadata": {
        "id": "ed1a4f52-f2d5-45d7-aeb2-a05ccab9e2fe"
      },
      "source": [
        "## Question 6\n",
        "#### What assumption does spectral clustering make? Why does this help us?\n",
        "\n",
        "The assumption that spectral clustering makes is that two points are more likely to be in the same cluster if they are close. This helps because it helps organize more messy data and makes it easier to interpret/organize the data. Additionally, this requires a similarity matrix instead of a guassian or vector space one. The data can be turned into a graph and eigenvectors to embed points into a low-dimensional connectivity space where clusters separate cleanly.   "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede993cf-222f-4c5b-b09e-bc2c988a777e",
      "metadata": {
        "id": "ede993cf-222f-4c5b-b09e-bc2c988a777e"
      },
      "source": [
        "## Question 7\n",
        "#### Define the gap statistic method. What do we use it for?\n",
        "\n",
        "Using data we can pick the number of clusters by comparing how tight the clusters are to what the expected random data is from the same state. This is used to chose K in clustering so see how many clusters we will have."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}